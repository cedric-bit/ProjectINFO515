Document: 0-prelim.pdf
infoh515 big data distributed data management scalable analytics preliminaries dimitrissacharidisgianlucabontempi 20242025 lecture outline generalcourseinformation 1 general course information course objective introducethefundamentalnotionsprinciplesandresearchresultsconcerning modernscalableandfaulttolerantwaysformanagingandanalyzingmassive amountsofdatausingparallelanddistributedsystems keyquestions whatisbigdatawhatarethecharacteristicsofsuchdata whatisacomputecluster howdoclustersstoredata howaretheyprogrammed whatarenotionsofefficiencyfordistributedalgorithms whatisbigdataanalytics howdoyouperformmachinelearningonbigdata 3 competences develop aftersuccessfulcompletionofthiscourseyoushouldbeableto 1 understandthecharacteristicsofbigdataandthechallengestheserepresent 2 knowtheprincipalarchitecturesofbigdatamanagementandanalytics systemsbeabletoexplainthepurposeofeachtheircomponentsandbeable torecognizeandexplainthekeypropertiesstrengthsandlimitationsofeach typeofsystemandtheircomponents 3 understandthekeybottlenecksinmanagingandanalyzingmassiveamountsof dataandbefamiliarwithmodernalgorithmsforovercomingthesebottlenecks usingparallelanddistributedcomputation 4 activelyusethisalgorithmicknowledgeinthedesignandimplementationof applicationsthatsolvecommondatamanagementandanalyticsproblems usingdifferenttypesofbdmas 5 buildaplicationsusingspecificinstancesofeachtypeofbdmas 4 2 acourseonhowtoinstallbigdataframeworks 3 anexhaustiveanddetailedlookintoallpossiblebigdataframeworksthat currentlyexist course 1 acourseonhowtobuildcomputeclusters 5 3 anexhaustiveanddetailedlookintoallpossiblebigdataframeworksthat currentlyexist course 1 acourseonhowtobuildcomputeclusters 2 acourseonhowtoinstallbigdataframeworks 5 course 1 acourseonhowtobuildcomputeclusters 2 acourseonhowtoinstallbigdataframeworks 3 anexhaustiveanddetailedlookintoallpossiblebigdataframeworksthat currentlyexist 5 infoh515 2 parts part1distributedmanagement lecturesbyprof dsacharidisulb dimitrissacharidisulbbe part2scalableanalytics lecturesbyprof gbontempiulb gianlucabontempiulbbe 6 prerequisites required goodprogrammingskills introductorycourseondatamanagement introductorycourseonalgorithmsanddatastructures introductorycourseonmachinelearning atulbinfof422statisticalfoundationsofmachinelearning atvub1002080cnrmachinelearningor4004728dnrtechniquesof artificialintelligence 7 infoh515 organization thecourseisorganizedasamixtureof lectures readingassignments projectwork 8 infoh515 organization part1 distributed management part2 scalableanalytics theory theory fridays10h12h fridays10h12h 14feb21mar 4apr23may ulbsolbosch ulbplainepforum sub4136sdc2206 exercises exercises wednesdays10h12h wednesdays10h12h tba 26feb5mar12mar19mar ulbsolboschtba checkuvandulbschedulesforscheduleandroomupdates httpswwwulbbeenschedules 9 infoh515 syllabus thesyllabusavailableatthevirtualuniversityconsistsof slides associatedreadingassignments coursematerialexercisesreadingassignmentsareallpublishedonthe ulbvirtualuniversity httpsuvulbacbecourseviewphpid124821 checkregularlyforupdates 10 infoh515 evaluation project60offinalscore writtenexam40offinalscore 11

Document: Stream Algos.pdf
chapter 4 mining data streams algorithms described book assume mining database data available want chapterweshallmakeanotherassumption dataarrivesinastreamorstreams andifitisnotprocessedimmediatelyorstoredthenitislostforever moreover shall assume data arrives rapidly feasible store allin activestorageie conventionaldatabaseandthen interactwith time choosing algorithms processing streams involve summarization streaminsomeway weshallstartbyconsideringhowtomakeausefulsample stream filter stream eliminate undesirable elements show estimate number different elements stream using much less storage would required listed elements seen anotherapproachtosummarizingastreamis tolookatonlyafixedlength window consisting last n elements typically large n query window relation database manystreamsandornis largewe maynotbe able storethe entire window every stream need summarize even windows address fundamentalproblemofmaintaininganapproximatecountonthenumberof1s inthewindowofabitstreamwhileusingmuchlessspacethanwouldbeneeded store entire window technique generalizes approximating various kinds sums 41 stream data model let us begin discussing elements streams stream processing explainthe difference betweenstreams anddatabasesandthe specialproblems arise dealing streams typical applications stream model applies examined 131 132 chapter 4 mining data streams adhoc queries streams entering 1 5 2 7 4 0 3 5 standing output streams q w e r u queries 0 1 1 0 1 0 0 0 stream processor time limited working storage archival storage figure 41 datastreammanagementsystem 411 datastreammanagement system analogy databasemanagementsystem view stream processor kind datamanagement system highlevel organization suggested fig 41 number streams enter system stream provide elements schedule need dataratesordatatypesandthetimebetweenelementsofonestreamneednot uniform fact rate arrival stream elements control system distinguishes stream processing processing ofdata goesonwithin databasemanagementsystem latter system controls rate data read disk therefore never worry data getting lost attempts execute queries streams may archived large archival store assume possible answer queries archival store could examined specialcircumstancesusing timeconsuming retrievalprocesses thereis also working store summaries parts streams may placed andwhichcanbe usedforansweringqueries workingstoremightbe disk oritmightbemainmemorydependingonhowfastweneedtoprocessqueries either way sufficiently limited capacity cannot store data streams 41 stream data model 133 412 examples stream sources beforeproceedingletusconsidersomeofthe waysinwhichstreamdataarises naturally sensor data imagine temperature sensor bobbing ocean sending back basestationareadingofthesurfacetemperatureeachhour thedataproduced sensor stream real numbers interesting stream since data rate low would stress modern technology entire stream could kept main memory essentially forever give sensor gps unit let report surface height instead temperature surface height varies quite rapidly compared tempera ture might sensor send back reading every tenth second sends 4byte real number time produces 35 megabytes per day still take time fill main memory let alone single disk one sensor might interesting learn something oceanbehaviorwemightwanttodeployamillionsensorseachsendingbacka stream rate ten per second million sensors isnt many would one every 150 square miles ocean 35 terabytes arriving every day definitely need think kept working storage archived image data satellites often send earth streams consisting many terabytes images per day surveillance cameras produce images lower resolution satellites many producing stream images intervals like one second london said six million cameras producing stream internet web traffic switching node middle internet receives streams ip packets many inputs routes outputs normally job switch transmit data retain query tendency put capability switch eg ability detect denialofservice attacks ability reroute packets based information congestion network websitesreceivestreamsofvarioustypes forexamplegooglereceivessev eral hundred million search queries per day yahoo accepts billions clicks per day various sites many interesting things learned streams example increase queries like sore throat enables us track spread viruses sudden increase click rate link could 134 chapter 4 mining data streams indicate news connected page could mean link broken needs repaired 413 stream queries therearetwowaysthatqueriesgetaskedaboutstreams weshowinfig41a placewithintheprocessorwherestandingqueriesarestored thesequeriesare sense permanently executing produce outputs appropriate times example 41 stream produced oceansurfacetemperature sen sor mentioned beginning section 412 might standing query output alert whenever temperature exceeds 25 degrees centigrade query easily answered since depends recent stream element alternativelywemighthaveastandingquerythateachtimeanewreading arrives produces average 24 recent readings query also canbeansweredeasilyifwestorethe24mostrecentstreamelements whena new streamelementarriveswe candropfromthe workingstore 25thmost recent element since never needed unless standing query requires another querywe mightask maximumtemperature everrecordedby sensor answer query retaining simple summary maximum stream elements ever seen necessary record entire stream new stream element arrives compare stored maximum set maximum whichever larger answer query producing current value maximum similarly want average temperature time record two values number readings ever sent stream sum readings adjust values easily time new reading arrives produce quotient answer query form query adhoc question asked current state stream streams store streams entirety normally cannot expect answer arbitrary queries streams idea kind queries asked adhoc query interface prepare storing appropriate parts summaries streams example 41 want facility ask wide variety adhoc queries common approach store sliding window stream working store sliding window recent n elements stream n elements arrived within last time units eg one day regardeachstreamelement asa tuple cantreatthe window asa relation query sql query course streammanagement system must keep window fresh deleting oldest elements new ones come 41 stream data model 135 example 42 web sites often like report number unique users pastmonth ifwethink ofeachloginasastreamelementwecanmaintain window logins recent month must associate arrival time login know longer belongs window think window relation loginsname time simple get number unique users past month sql query select countdistinctname logins time constant represents time one month current time note must able maintain entire stream logins past month working storage however even largest sites data terabytes surely stored disk 414 issues stream processing proceeding discuss algorithms let us consider constraints whichweworkwhendealingwithstreams firststreamsoftendeliverelements veryrapidly wemustprocesselementsinrealtimeorwelosetheopportunity process without accessing archivalstorage thus often important streamprocessing algorithm executed main memory without access secondary storage rare accesses secondary storage moreoverevenwhenstreamsareslowasinthesensordataexample ofsection412theremaybemanysuchstreams evenifeachstreambyitself canbeprocessedusingasmallamountofmainmemorytherequirementsofall streams together easily exceed amount available main memory thus many problems streaming data would easy solve enough memory become rather hard require invention new techniques order execute realistic rate machine realistic size two generalizations stream algorithms worth bearing mind read chapter often much efficient get approximate answer problem exact solution asinchapter 3avarietyoftechniques relatedtohashingturnoutto useful generally techniques introduce useful randomness algorithms behavior order produce approximate answer close true result 136 chapter 4 mining data streams 42 sampling data stream first example managing streaming data shall look extracting reliable samples stream many stream algorithms trick involves using hashing somewhat unusual way 421 motivating example thegeneralproblemweshalladdressisselectingasubsetofastreamsothatwe ask queries selected subset answers statistically representative stream whole know queries askedthenthereareanumberofmethodsthatmightworkbutwearelooking technique allow adhoc queries sample shall look particular problem general idea emerge running example following search engine receives stream queriesanditwouldliketostudythebehavioroftypicalusers1 weassumethe stream consists tuples user query time suppose want answer queries fraction typical users queries repeated pastmonth assume alsothatwe wishto store only110thofthe stream elements theobviousapproachwouldbetogeneratearandomnumbersayaninteger 0 9 response eachsearchquery store tuple random number 0 user average 110th queries stored statistical fluctuations introduce noise data users issue many queries law large numbers assure us users fraction quite close 110th queries stored however scheme gives us wrong answer query asking average number duplicate queries user suppose user issued search queries one time past month search queries twice searchqueriesmorethantwice ifwehavea110thsampleofqueriesweshall see sample user expected s10 search queries issued search queries issued twice d100 appear twice sample fraction times probability occurrences querywillbe inthe 110thsample ofthe queriesthatappeartwice inthe full stream 18d100 appear exactly see note 18100 probability one two occurrences 110thof stream selected 910th selected correct answer query fraction repeated searches dsd howevertheanswerweshallobtainfromthesampleisd10s19d toderivethelatterformulanotethatd100appeartwicewhiles1018d100 appearonce thusthe fractionappearingtwice inthe sampleis d100divided 1whileweshallrefertousersthesearchenginereallyreceivesipaddressesfromwhich thesearch querywasissued weshallassumethat ipaddresses identifyunique users whichisapproximatelytruebutnotexactlytrue 42 sampling data stream 137 d100s1018d100 ratio d10s19d positive values dsdd10s19d 422 obtaining representative sample query section 421 like many queries statistics typical users cannot answered taking sample users search queries thus muststrive pick 110thofthe usersandtake alltheir searchesfor sample taking none searches users store list users whether sample could following time search query arrives stream look user see whether sample add search query sample however record ever seen user generate random integer 0 9 number 0 add user list value number 0 add user value thatmethodworksas longas wecanaffordto keepthe listofallusersand theirinoutdecisioninmainmemorybecause thereisnttime togotodisk every search arrives using hash function one avoid keeping list users hash user name one ten buckets 0 9 user hashes bucket 0 accept searchquery sample note actually store user bucket fact data buckets effectively use hash function random numbergeneratorwiththeimportantpropertythatwhenappliedtothesame userseveraltimeswealwaysgetthe samerandomnumber thatiswithout storing inout decision user reconstruct decision time search query user arrives generally obtain sample consisting rational fraction ab users hashing user names b buckets 0 b1 add search query sample hash value less 423 general sampling problem running example typical following general problem stream consists tuples n components subset components key componentsonwhichtheselectionofthesamplewillbebased inourrunning example three components user query time user key however could also take sample queries making query key even take sample userquery pairs making components form key take sample size ab hash key value tuple b buckets accept tuple sample hash value less key consists one component hash function needs combine values components make single hashvalue 138 chapter 4 mining data streams result sample consisting tuples certain key values selectedkey values willbe approximatelyab ofallthe key values appearing stream 424 varying sample size often sample grow stream enters system running example retain search queries selected 110th users forever time goes searches users accumulated new users selected sample appear stream budget many tuples stream stored sample fraction key values must vary lowering time goes orderto assure thatat alltimes sample consistsof alltuples froma subset ofthe key values choose hashfunction h fromkey values largenumberofvalues01b1 wemaintainathresholdtwhichinitially largest bucket number b1 times sample consists tuples whose key k satisfies hk new tuples stream added sample satisfy condition number stored tuples sample exceeds allotted space lowerttot1andremovefromthesampleallthosetupleswhosekeyk hashes efficiency lower 1 remove tuples severalof highest hash values whenever need throw key values sample efficiency obtained maintaining index hash value find tuples whose keys hash particular value quickly 425 exercises section 42 exercise 421 suppose stream tuples schema gradesuniversitycourseid studentid grade assume universities unique courseid unique within uni versity ie different universities may different courses id eg cs101 likewise studentids unique within university different universities may assign id different students suppose want answer certain queries approximately 120th sample data queries indicate would construct sample tell key attributes universityestimate averagenumber students course b estimate fraction students gpa 35 c estimate fractionof courseswhereat leasthalfthe students gota 43 filtering streams 139 43 filtering streams another common process streams selection filtering want accept tuples stream meet criterion accepted tuples passed another process stream tuples dropped selection criterion property tuple calculated eg first component less 10 selection easy problem becomes harder criterion involves lookup membership set especially hard set large store main memory section shall discuss technique known bloom filtering way eliminate tuples meet criterion 431 motivating example let us start running example illustrates problem suppose set one billion allowedemail addresses allow believe spam stream consists pairs email address email since typicalemailaddressis20bytes ormoreitis notreasonableto store inmainmemory thuswecaneitherusedisk accessesto determinewhether ornottoletthroughanygivenstreamelementorwecandeviseamethodthat requires main memory availableand yet filter undesired stream elements suppose arguments sake one gigabyte available main memory technique knownas bloom filtering use main memory bit array case room eight billion bits since one byte equalseightbits deviseahashfunctionhfromemailaddressestoeightbillion buckets hash member bit set bit 1 bits array remain 0 since one billion members approximately 18th bits 1 exact fraction bits set 1 slightly less 18th possible two members hash bit shall discusstheexactfractionof1sinsection433 whenastreamelementarrives hash email address bit email address hashes 1 let email email address hashes 0 certain address drop stream element unfortunately spam email get approximately 18th stream elements whose email address happen hash bitwhosevalueis1andwillbeletthrough neverthelesssincethe majorityof emails spam 80 according reports eliminating 78th thespamisasignificantbenefit moreoverifwewanttoeliminateeveryspam need check membership good bad emails get filter checks require use secondary memory access arealso optionsas shall see study generalbloomfilteringtechnique asasimpleexamplewecoulduseacascade 140 chapter 4 mining data streams filters would eliminate 78th remaining spam 432 bloom filter bloom filter consists 1 array n bits initially 0s 2 collection hash functions h h h hash function maps 1 2 k key values n buckets corresponding n bits bitarray 3 set key values purpose bloom filter allow stream elements whose keys rejecting stream elements whose keys initialize bit array begin bits 0 take key value hash using k hash functions set 1 bit h k hash function h key value k test key k arrives stream check h kh kh k 1 2 k 1s bitarray 1s let stream element one bits 0 k could reject stream element 433 analysis bloom filtering key value element surely pass bloom filter however key value might still pass need understand calculate probability false positive function n bitarray length number members k number hash functions model use throwing darts targets suppose x targets darts dart equally likely hit target throwing darts many targets expect hit least analysis similar analysis section 342 goes follows probability given dart hit given targetis x1x probabilitythatnone ofthe dartswillhit giventargetis x1 x write expression 1 1x xy x usingtheapproximation11 1eforsmallrecallsection135 weconcludethattheprobabilitythatnoneoftheydartshitagiventarget eyx 43 filtering streams 141 example 43 consider running example section 431 use calculation get true expected number 1s bit array think bit target member dart probability given bit 1 probability corresponding target hit one darts since one billion members 109 darts eight billion bits x8109 targets thus probability given target hit eyx e18 probability hit 1e18 quantity 01175 section 431we suggestedthat 18 0125is goodapproximationwhich exact calculation apply rule general situation set members array n bits k hash functions number targets x n number darts km thus probability bit remains 0 ekmn want fraction 0 bits fairly large else probability nonmember hash least 0 becomes small many false positives example might choose k number hash functions nm less probability 0 least e1 37 general probability false positive probability 1 bit 1ekmn raised kth power ie 1ekmnk example 44 inexample43wefoundthatthefractionof1sinthearrayof ourrunningexampleis01175andthisfractionisalsotheprobabilityofafalse positive nonmember pass filter hashes 1 probability 01175 suppose used array used two different hash functions situation corresponds throwing two billion darts eightbillion targetsandthe probabilitythat bit remains 0 e14 inorder false positive nonmember must hash twice bits 1 probability 1e142 approximately 00493 thus adding secondhash function running example improvementreducing falsepositive rate 01175 00493 434 exercises section 43 exercise 431 situation running example 8 billion bits 1 billion members set calculate falsepositive rate use three hash functions use four hash functions exercise 432 suppose n bits memory available set members instead using k hash functions could divide n bits k arraysand hash array function n k probability false positive compare using k hash functions single array 142 chapter 4 mining data streams exercise 433 function n number bits number members set number hash functions minimizes false positive rate 44 counting distinct elements stream section look third simple kind processing might want stream previous examples sampling filtering somewhat tricky want reasonable amount main memory soweuseavarietyofhashingandarandomizedalgorithmtogetapproximately want little space needed per stream 441 countdistinct problem suppose stream elements chosen universal set would like know many different elements appeared stream counting either beginning stream known time past example 45 useful example ofthis problemconsider website gath eringstatisticsonhowmanyunique usersithasseenineachgivenmonth universalsetisthe setofloginsforthatsite andastreamelementisgenerated eachtime someone logsin measure appropriatefor site like amazon typical user logs unique login name similar problem web site like google require login issue search query may able identify users ip address send query 4 billion ip addresses2 sequences four 8bit bytes serve universal set case theobviouswaytosolvetheproblemistokeepinmainmemoryalistofall theelementsseensofarinthestream keeptheminanefficientsearchstructure hash table search tree one quickly add new elements check whether element arrived stream already seen aslongasthenumberofdistinctelementsisnottoogreatthis structure fit main memory little problem obtaining exact answer question many distinct elements appear stream howeverif number distinct elements great many streams need processed eg yahoo wants count number unique users viewing pages month cannot store needed data main memory several options could use machines machine handling one several streams could store data structure secondary memory batch stream elements whenever brought disk block main memory would many tests updates performed data block could use strategy discussed section 2atleastthatwillbethecaseuntilipv6becomes thenorm 44 counting distinct elements stream 143 estimate number distinct elements use much less memory number distinct elements 442 flajoletmartin algorithm possible estimate number distinct elements hashing ele ments universalsetto bitstring sufficiently long lengthof bitstringmustbe sufficientthattherearemorepossibleresultsofthehash function elements universal set example 64 bits sufficientto hashurls shallpickmanydifferenthashfunctions andhash eachelementofthestreamusingthesehashfunctions theimportantproperty ofahashfunctionisthatwhenappliedtothesameelementitalwaysproduces result notice property also essential sampling technique section 42 idea behind flajoletmartin algorithm different elements see stream different hashvalues shall see see different hashvalues becomes likely one values unusual particular unusual property shall exploit value ends many 0s although many options exist whenever apply hash function h stream element bit string ha end number 0s possibly none call number tail length h let r maximum tail length seen far stream shall use estimate 2r number distinct elements seen stream estimate makes intuitive sense probability given stream elementa hasha ending atleastr 0sis 2r suppose arem distinct elements stream thenthe probability none ofthem tail length least r 12rm sort expression familiar rewrite 12r2r m2r assuming r reasonably large inner expression form 11 approximately 1e thus probability finding stream element many r 0s end hash value em2r conclude 1 much largerthan 2r probability shall find tail length least r approaches 1 2 much less 2r probability finding tail length least r approaches 0 conclude two points proposed estimate 2r recall r largest tail length stream element unlikely either much high much low 144 chapter 4 mining data streams 443 combining estimates unfortunatelythereisatrapregardingthestrategyforcombiningtheestimates number distinct elements obtain using many dffierent hash functions first assumption would take average values 2r get hash function shall get value approaches true hash functions use however case reason influence overestimate average consider value r 2r much larger probabilitypthatwe shalldiscoverr largestnumberof0satthe end hash value stream elements probability finding r1 largestnumber of0s insteadis atleastp2 howeverif increase 1 number 0s end hash value value 2r doubles consequently contribution possible large r expectedvalueof2r growsasrgrowsandtheexpectedvalueof2r isactually infinite3 another way combine estimates take median estimates medianis notaffected occasionaloutsizedvalue of2r sothe worry described averageshould carry median unfortu nately median suffersfromanother defect alwaysa powerof 2 thus matter many hash functions use correct value two powers 2 say 400 impossible obtain close estimate solution problem however combine two methods first group hash functions small groups take average take median averages true occasional outsized 2r bias groups make large however taking median group averages reduce influence effect almost nothing moreover groups large enough averages essentially number enables us approach true value long use enough hash functions order guarantee possible average obtained groups size least small multiple log 2 444 space requirements observe read stream necessary store elements seen thing need keep main memory one integer per hash function integer records largest tail length seen far hash function stream element processing one stream could use millions hash functions far need get 3technically since hash value bitstring finite length contribution 2r rs larger length hash value however effect enoughtoavoidtheconclusionthattheexpected valueof2r ismuchtoolarge 45 estimating moments 145 closeestimate onlyifwearetryingto processmanystreamsatthe time wouldmainmemoryconstrainthe numberofhashfunctions wecouldassociate one stream practice time takes compute hash values eachstreamelementwouldbe moresignificantlimitationonthe number hash functions use 445 exercises section 44 exercise 441 suppose streamconsists integers 3 1 4 1 5 9 2 65 ourhashfunctions willallbe ofthe formhxaxb mod 32for b treat result 5bit binary integer determine taillength foreachstreamelement andthe resulting estimate ofthe number distinct elements hash function hx2x1 mod 32 b hx3x7 mod 32 c hx4x mod 32 exercise 442 yousee anyproblemswith choiceofhashfunctions exercise 441 advice could give someone going use hash function form hxaxb mod 2k 45 estimating moments section consider generalizationof problem counting distinct elements stream problem called computing moments involves distribution frequencies different elements stream shall define moments orders concentrate computing second moments general algorithm moments simple extension 451 definition moments suppose streamconsists ofelements chosenfroma universalset assume universal set ordered speak ith element let number occurrences ith element kthorder moment kth moment stream sum k example 46 the0thmomentisthesumof1foreachm thatisgreaterthan 04 0th moment count number distinct elements stream use method section 44 estimate 0th moment stream 4technicallysincem couldbe0forsomeelementsintheuniversalsetweneedtomake explicit definition moment 00 taken 0 moments 1 thecontributionofm isthatare0issurely0

